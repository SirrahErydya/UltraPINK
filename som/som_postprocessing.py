"""
Process the binary files generated by PINK to get usable database entries
"""
import numpy as np
import pandas
import struct
import os
import matplotlib.pyplot as plt
import seaborn as sns
import astropy.visualization as vis


######################################################################################
#           SOM Process functions                                                    #
######################################################################################
class SOM(object):
    """
    Class to represent a (trained) SOM object.
    """
    def __init__(self,  dataset_name, som_path, mapping_path,
                 som_label='- 15x15'):

        # Unpack the data
        (data_som, number_of_channels, som_width, som_height, som_depth,
         neuron_width, neuron_height, layout) = unpack_trained_som(som_path)

        self.training_dataset_name = dataset_name
        self.data_som = data_som
        self.som_width = som_width
        self.som_height = som_height
        self.som_depth = som_depth
        self.number_of_channels = number_of_channels
        self.layout = layout
        self.som_label = som_label
        self.rotated_size = neuron_width
        self.full_size = int(np.ceil(self.rotated_size * np.sqrt(2)))

        # Load mapping
        data_map, no_imgs = self.load_som_mapping(mapping_path)
        self.data_map = data_map
        self.number_of_images = no_imgs

        # Training parameters
        if self.som_width != None or self.som_height != None:
            self.gauss_start = max(self.som_width, self.som_height) / 2
        self.learning_constraint = 0.05
        self.epochs_per_epoch = 1
        self.gauss_decrease = 0.95
        self.gauss_end = 0.3
        self.pbc = "True"
        self.learning_constraint_decrease = 0.95
        self.random_seed = 42
        self.init = "random_with_preferred_direction"
        self.pix_angular_res = 1.5
        self.rotated_size_arcsec = self.rotated_size * self.pix_angular_res
        self.full_size_arcsec = self.full_size * self.pix_angular_res

    def print(self):
        print("\nSOM ID{som.run_id} info".format(som=self))
        print("Input data dimensions: ({som.fullsize}x{som.fullsize}x{som.number_of_channels})".format(som=self))
        print("Neuron/prototype dimensions: ({som.rotated_size}x{som.rotated_size}x{som.number_of_channels})".format(som=self))
        print("SOM dimensions: ({som.som_width}x{som.som_height}x{som.som_depth}), layout {som.layout}"
              .format(som=self))
        print("Train parameters:")
        print("Periodic boundary conditions: {som.pbc}".format(som=self))
        print("learn. constr. {som.learning_constraint}, decrease {som.learning_constraint_decrease}".format(som=self))
        print("Neighborhood function: start {som.gauss_start}, decrease {som.gauss_decrease}, som {som.gauss_end}\n"
              .format(som=self))

    def load_som_mapping(self, mapping_path, verbose=True):
        """
        Load distances of cut-outs to a trained SOM, also returning
        the number of cut-outs mapped to the SOM, and the width, height and depth
        of this SOM. Requires the file path to the mapping binary file and the
        layout of the trained SOM (either quadratic or hexagonal)
        :param mapping_path:
        :param verbose:
        :return:
        """
        # Create list of indexes to retrieve coordinates of the cut-outs
        cut_out_index = []

        # Unpack SOM mapping
        if not os.path.exists(mapping_path):
            print('This file does not exist:', mapping_path)
        with open(mapping_path, 'rb') as inputStream:
            inputStream.read(12)    # Skip first 3 numbers of header info
            number_of_images = struct.unpack("i", inputStream.read(4))[0]
            inputStream.read(8)     # Skip layout and dimensions
            som_width = struct.unpack("i", inputStream.read(4))[0]
            som_height = struct.unpack("i", inputStream.read(4))[0]
            failed = 0
            print(self.som_width, som_width)
            print(self.som_height, som_height)
            assert self.som_width == som_width
            assert self.som_height == som_height

            if self.layout == 1:
                map_size, _ = get_hex_size(som_width)
            else:
                map_size = som_width * som_height * self.som_depth

            data_map = np.ones((number_of_images, map_size))
            for i in range(number_of_images):
                for t in range(map_size):
                    try:
                        data_map[i, t] = struct.unpack_from("f", inputStream.read(4))[0]
                        if t == 0:
                            cut_out_index.append(i)  # add index
                    except:
                        failed += 1
            data_map = data_map[:len(cut_out_index)]
            print(data_map.shape)
            if failed > 0:
                print('Failed:', int(1.0 * failed / map_size))
        if verbose:
            print('''Loaded distances of {} cut-outs to a SOM with a width, height 
                and depth equal to {},{},{}.'''.format(number_of_images, som_width, som_height, self.som_depth))
            return data_map, number_of_images


######################################################################################
#           Plotter function                                                         #
######################################################################################
def plot_image(img, save_path):
    fig = plt.figure()
    fig.set_size_inches(6, 6)
    ax = plt.Axes(fig, [0., 0., 1., 1.])
    ax.set_axis_off()
    fig.add_axes(ax)
    ax.imshow(img, aspect='equal', interpolation="nearest",
              origin='lower')
    plt.savefig(save_path)
    plt.close()


######################################################################################
#           Helper for Initialization                                                #
######################################################################################
def unpack_trained_som(trained_path):
    """
    Unpacks a trained SOM, returns the SOM with hexagonal layout
    in a flattened format. Requires the file path to the trained SOM and
    its layout (either quadratic or hexagonal)
    """
    with open(trained_path, 'rb') as inputStream:
        failures = 0
        # File structure for Pink 2.0:
        # 2 1 <data-type> <som layout: (layout, dimensions, width, height)>
        # <neuron layout: (layout, dimensions, width, height)> <data>
        inputStream.read(12)    # Skip first 3 numbers of header info
        layout = struct.unpack("i", inputStream.read(4))[0]
        inputStream.read(4)   # Skip SOM dimensions
        som_width = struct.unpack("i", inputStream.read(4))[0]
        som_height = struct.unpack("i", inputStream.read(4))[0]
        inputStream.read(8)     # Skip neuron layout and dimensions
        neuron_width = struct.unpack("i", inputStream.read(4))[0]
        neuron_height = struct.unpack("i", inputStream.read(4))[0]

        # Todo: where do these values come from?
        som_depth = 1
        number_of_channels = 1

        if layout == 0: # Quadratic
            data_som = np.ones(
                (som_width, som_height, som_depth, number_of_channels * neuron_width * neuron_height))
            for i in range(som_width):
                for ii in range(som_height):
                    for iii in range(som_depth):
                        for iv in range(number_of_channels * neuron_width * neuron_height):
                            try:
                                data_som[i, ii, iii, iv] = struct.unpack_from(
                                    "f", inputStream.read(4))[0]
                            except:
                                failures += 1.0
        else:
            som_size, _ = get_hex_size(som_width)
            data_som = np.ones((som_size, number_of_channels * neuron_width * neuron_height))
            for i in range(som_size):
                for ii in range(number_of_channels * neuron_width * neuron_height):
                    try:
                        data_som[i, ii] = struct.unpack_from("f", inputStream.read(4))[0]
                    except:
                        failures += 1.0
        if failures > 0:
            print('Failures:', int(failures / (number_of_channels * neuron_width * neuron_height)))
        return data_som, number_of_channels, som_width, som_height, som_depth, neuron_width, neuron_height, layout


def get_hex_size(hex_length):
    """
    Returns number of nodes in the hexmap (hex_size) with dimensions hex_length
    x hex_length.
    Also returns the indexes of the nodes per row of the hexmap (hex_map)
    :param hex_length:
    :return:
    """
    hex_size = 0; last = 0; hex_map = []
    for t in range(int(hex_length/2)+1, hex_length+1):
        hex_map.append(list(range(last,t+last)))
        hex_size += t
        last += t
    for t in range(hex_length-1, int(hex_length/2),-1):
        hex_map.append(list(range(last,t+last)))
        hex_size += t
        last += t
    return hex_size, hex_map


def populate_hex_map(filler, som_width, som_height):
    hex_size, hex_map = get_hex_size(som_width)
    filler_map = np.empty([som_width, som_height], dtype=type(filler[0]))
    filler_mask = np.ones([som_width, som_height], dtype=np.bool)

    map_y = 0
    map_x = abs((som_height-1)/2 - map_y)
    map_x = map_x / 2 + map_x % 2 - 1
    for f in filler:
        map_x = map_x + 1
        off = abs((som_height-1)/2 - map_y)
        if map_x >= som_width - np.floor(off / 2) - off % 2 * map_y % 2:
            map_y = map_y + 1
            map_x = abs((som_height-1)/2 - map_y)
            map_x = np.floor(map_x / 2) + map_x % 2 * (1-map_y) % 2
        # print(int(mapX),mapY, proto_count)
        filler_map[int(map_x), int(map_y)] = f
        filler_mask[int(map_x), int(map_y)] = False
    return filler_map, filler_mask


def return_cutout(bin_path, cutout_id):
    """Open bin_path, return cut-out with id=cutout_id"""
    with open(bin_path, 'rb') as file:
        file.read(12)   # Skip first 3 numbers of header info
        number_of_images = struct.unpack("i", file.read(4))[0]
        file.read(8)    # Skip layout info
        width = struct.unpack("i", file.read(4))[0]
        height = struct.unpack("i", file.read(4))[0]
        if cutout_id > number_of_images:
            raise Exception('Requested image ID is larger than the number of images.')
        size = width * height
        file.seek((cutout_id + 0) * size*4, 1)
        array = np.array(struct.unpack('f' * size, file.read(size*4)))
        cutout = np.ndarray([width,height], 'float', array)
        return cutout



